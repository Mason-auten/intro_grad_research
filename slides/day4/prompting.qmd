---
title: "AI: The Butlerian Jihad"
subtitle: "Introduction to Graduate Research"
format: 
  clean-revealjs:
    echo: true
  html-math-method:
    method: mathjax
    url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: Mason Auten
    email: mason.auten@vanderbilt.edu
    affiliations: Vanderbilt University
  - name: Patrick Buhr
    email: patrick.buhr@vanderbilt.edu
    affiliations: Vanderbilt University
date: today
self-contained: true
bibliography: skills_camp.bib
---

# Crash Course on Prompting

## How It Works

- Think about how an LLM works.
- It tries to predict the next word in the sentence.
- We can think about it as a chain of conditional probabilities:
  - $P(w_n \mid w_1, w_2, \dots, w_{n-1})$
    - What is the probability that the $n$-th word is $w_n$ **given** the preceding words $w_1, \dots, w_{n-1}$?

## Conditional Probabilities

- LLMs are essentially sequences of probabilities, which can be expressed like a joint probability:

$$
\begin{aligned}
P(w_1, w_2, \dots, w_n)
&= P(w_1)\,P(w_2 \mid w_1)\,P(w_3 \mid w_1, w_2)\cdots P(w_n \mid w_1, \dots, w_{n-1}) \\
&= P(w_1)\prod_{k=2}^{n} P(w_k \mid w_1, \dots, w_{k-1})
\end{aligned}
$$

## General Advice

- Use AI as a complement, not a substitute, for learning.  
- You are responsible for anything you turn in.  
- If Chat gets it wrong, you get it wrong.
- AI produces bullshit [@hicks2024ChatGPTBullshit].


## Practical Advice

- Be specific when prompting Chat.
- Instead of “fix this code,” try:
  > I’m doing a data analysis project in political science. My dependent variable is war and my independent variable is economic activity. I want to graph the relationship between GDP and civil war occurrence. Help me create a scatter plot that shows...

## Principles

- Give it context.
- Be precise ..avoid vague instructions.
- Tell it to act as the role you need.
- Break tasks into smaller steps.

## Principles Cont.
- Repeat and iterate.
- Give Chat a better base to work from.
- Try prompt chaining.

## Chain Prompting

- **What it is:** Breaking a complex request into smaller, logically ordered prompts, each building on the output of the last.
- **Why it works:**  
  - Forces the model to focus on one subtask at a time.  
  - Reduces confusion and error propagation.  
  - Lets you correct or refine before moving forward.

## Chain Prompting Cont. 
- **Example:**
  1. "Summarize this article in three bullet points."
  2. "Now, rewrite those bullet points in plain language for a public audience."
  3. "Suggest three related research questions based on that summary."
- **Tip:** Keep a consistent thread. Copy the relevant part of the last answer into the next prompt.



## Chat Experiences {.incremental}

::::: columns
::: column
**What’s it good at?**

- Writing code
- Answering questions about code
:::

::: column
**What’s it not so good at?**

- Critiquing your writing
- Writing itself
- Coming up with research topics
- Being your therapist
:::
:::::

## References 

